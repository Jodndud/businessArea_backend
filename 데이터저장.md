# 데이터 저장 기능 개발: 문제 해결 과정 요약 (Troubleshooting Log)

## 개요
외부 API(학교알리미, 상권정보)를 호출하여 데이터를 가공하고, 로컬 MySQL 데이터베이스에 저장하는 기능을 개발하는 과정에서 발생한 다양한 기술적 문제와 해결 과정을 기록합니다.

---

## 1. 학교 정보 저장 (학교알리미 API)

### 1-1. SSL/TLS 인증 오류
- **문제 상황:** `http`를 `https`로 변경 후 API 호출 시, `PKIX path building failed` 또는 `unable to find valid certification path` 오류가 발생하며 연결에 실패했습니다.
- **원인 분석:**
    1.  `schoolinfo.go.kr` 서버의 SSL 인증서를 발급한 인증 기관(CA)을 프로젝트를 실행하는 자바(JVM)가 신뢰하지 못하는 상태였습니다.
    2.  `keytool`로 인증서를 추가했음에도 문제가 지속되었는데, 이는 **터미널에서 사용한 시스템 JDK와 인텔리제이(IDE)가 프로젝트 실행에 사용한 내장 JDK가 달라서** 발생한 문제임이 확인되었습니다. 인증서가 엉뚱한 JDK에 추가되고 있었던 것입니다.
- **해결 과정:**
    1.  웹 브라우저의 인증서 보기 기능에서 '중간 인증서'를 파일(`.crt`)로 다운로드했습니다.
    2.  IDE의 `Project Structure` 설정에서 현재 프로젝트가 사용하는 JDK의 정확한 경로를 확인했습니다.
    3.  확인된 IDE용 JDK 경로를 명시하여, 해당 경로의 `cacerts` 파일에 다운로드한 중간 인증서를 `keytool` 명령어로 직접 추가했습니다.
    4.  IDE를 재시작하여 변경된 신뢰 목록을 적용함으로써 문제를 해결했습니다.

### 1-2. 대용량 응답 처리 오류
- **문제 상황:** SSL 문제가 해결된 후, 일부 학교급(초/중/고) 조회 시 `DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144` 오류가 발생했습니다.
- **원인 분석:** API의 JSON 응답 데이터 크기가 Spring WebClient의 기본 메모리 버퍼 크기인 256KB를 초과했습니다. 이는 메모리 오버플로우를 방지하기 위한 WebClient의 기본 안전장치입니다.
- **해결 과정:**
    1.  `WebClientConfig.java` 설정 파일을 생성했습니다.
    2.  `@Bean`을 통해 `WebClient`를 직접 생성하며, `ExchangeStrategies`를 사용하여 메모리 버퍼 크기를 10MB로 넉넉하게 상향 조정했습니다.
    ```java
    ExchangeStrategies exchangeStrategies = ExchangeStrategies.builder()
        .codecs(configurer -> configurer.defaultCodecs().maxInMemorySize(10 * 1024 * 1024)) // 10MB
        .build();

    return WebClient.builder()
            .exchangeStrategies(exchangeStrategies)
            .build();
    ```
    3.  서비스 클래스에서는 `WebClient`를 직접 생성하는 대신, 설정 파일에 등록된 Bean을 의존성 주입(`DI`)받아 사용하도록 수정했습니다.

### 1-3. 데이터베이스 연결 오류
- **문제 상황:** 애플리케이션 실행 시 `java.sql.SQLNonTransientConnectionException: Public Key Retrieval is not allowed` 오류가 발생했습니다.
- **원인 분석:** 최신 MySQL JDBC 드라이버는 보안 강화를 위해, 암호화되지 않은(non-SSL) 연결에서는 서버의 공개키를 가져오는 것을 기본적으로 차단합니다.
- **해결 과정:**
  `application.properties`의 데이터베이스 연결 URL 끝에 `&allowPublicKeyRetrieval=true` 옵션을 추가하여, 드라이버가 공개키를 가져오도록 명시적으로 허용해주었습니다.
    ```properties
    spring.datasource.url=...&allowPublicKeyRetrieval=true
    ```

---

## 2. 업종 코드 저장 (소상공인시장진흥공단 API)

### 2-1. API 인증 및 응답 형식 오류
- **문제 상황:** API 호출 시 `UnsupportedMediaTypeException: Content type 'text/xml;charset=UTF-8' not supported` 오류가 발생했습니다. Postman에서는 JSON으로 정상 응답을 확인했지만, 코드 실행 시에는 XML이 반환되었습니다.
- **원인 분석:**
    1.  API 명세 확인 결과, 해당 API는 `Authorization` 헤더와 `serviceKey` 쿼리 파라미터 두 가지 방식의 인증을 모두 요구하는 것으로 추정되었습니다. 코드에서는 한 가지 방식만 사용하고 있어 인증에 실패했고, 서버가 기본 에러 포맷인 XML로 응답한 것입니다.
    2.  API 키 값 자체에 URL 예약 문자인 `=`가 포함되어 있어, URL 생성 과정에서 `Invalid character '=' for QUERY_PARAM` 오류를 유발했습니다.
- **해결 과정:**
    1.  **이중 인증 적용:** `WebClient` 요청 시 `.header("Authorization", authKey)`와 `.queryParam("serviceKey", serviceKey)`를 모두 추가하여 두 가지 인증을 동시에 처리했습니다.
    2.  **URL 인코딩:** `serviceKey` 값을 `URLEncoder.encode()`를 사용하여 수동으로 인코딩한 후, `queryParam`에 전달하여 `=` 문자가 URL에서 안전하게 처리되도록 수정했습니다.

### 2-2. 소분류 데이터 조회 시 타임아웃 추정 오류
- **문제 상황:** 대/중분류는 성공적으로 저장되나, 데이터 양이 많은 소분류 조회 단계에서만 다시 `UnsupportedMediaTypeException` (XML 응답) 오류가 반복되었습니다.
- **원인 분석:** 특정 중분류에 속한 소분류 데이터의 양이 너무 많아, API 서버가 응답을 생성하는 데 시간이 오래 걸려 내부적으로 타임아웃이 발생하고, 결국 기본 에러 포맷인 XML을 반환하는 것으로 추정되었습니다.
- **해결 과정:**
    1.  하나의 긴 프로세스를 실행하던 서비스 로직을 **대/중/소분류 각각을 독립적으로 실행할 수 있는 3개의 `public` 메서드**로 분리했습니다.
    2.  컨트롤러 역시 각 단계를 실행하는 **3개의 개별 API 엔드포인트** (`/save-lcls`, `/save-mcls`, `/save-scls`)를 갖도록 수정했습니다.
    3.  가장 문제가 되었던 `fetchAndSaveScls` 메서드 내부에 **페이지네이션(Pagination) 로직**을 추가했습니다. `while` 루프를 사용하여 `pageNo`를 1씩 증가시키며 모든 페이지의 데이터를 나누어 가져오도록 구현하여, 단일 요청의 부하를 줄였습니다.

## 3. 업종코드의 모든 상가데이터 (소상공인시장진흥공단 API)

### 3-1. 너무 많은 데이터, 저장시간 오래걸림
- 비동기로 처리

## 최종 요약 및 교훈

초기 API 연결부터 데이터 파싱, 대용량 처리, 환경 설정 문제에 이르기까지 다양한 문제들을 체계적으로 해결했습니다. 이 과정을 통해 다음과 같은 중요한 교훈을 얻을 수 있었습니다.

- **API 명세는 항상 재확인해야 한다:** 인증 방식, 파라미터, 응답 구조 등은 공식 문서를 통해 정확히 확인하는 것이 중요하다.
- **환경의 차이를 인지해야 한다:** 터미널(시스템 JDK)과 IDE(내장 JDK)의 환경 차이가 SSL 인증 같은 문제의 원인이 될 수 있다.
- **대용량 데이터는 나누어 처리한다:** 타임아웃과 서버 부하를 피하기 위해 페이지네이션은 필수적인 전략이다.
- **로그는 최고의 디버깅 도구다:** 문제가 발생했을 때, 요청 URL과 서버의 원본 응답을 직접 출력해보는 것이 원인 파악에 가장 효과적이다.